{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyTorch_tutorial",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/zerojsh00/bigdata/blob/master/pyTorch_tutorial.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "4Yyy3b6oO_43",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Colab 에서 pyTorch 를 사용하기 위해 설치하는 과정입니다."
      ]
    },
    {
      "metadata": {
        "id": "44YML9n3Oz-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "accelerator = 'cu80' if os.path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6HKT4JZPj-N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "pyTorch 를 비롯해 오늘 실습에 필요한 파이썬 라이브러리를 읽어들입니다.\n",
        "\n",
        "그리고 라이브러리의 버전을 출력합니다."
      ]
    },
    {
      "metadata": {
        "id": "IuzCRF08O_mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9bb97cec-e6f3-4c8e-b169-ede8bd42f1e8"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import timeit\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "#plt.rc('text', usetex = True)\n",
        "mpl.rcParams[\"font.family\"] = \"serif\"\n",
        "mpl.rcParams[\"font.size\"] = \"15\"\n",
        "\n",
        "print('python version : ', sys.version)\n",
        "print('numpy version : ', np.version.version)\n",
        "print('matplotlib version :', mpl.__version__)\n",
        "print('pytorch version : ', torch.__version__)\n",
        "print('Cuda : ', torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python version :  3.6.3 (default, Oct  3 2017, 21:45:48) \n",
            "[GCC 7.2.0]\n",
            "numpy version :  1.14.5\n",
            "matplotlib version : 2.1.2\n",
            "pytorch version :  0.4.0\n",
            "Cuda :  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QQiWGAjfQekJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "구현할 모델의 하이퍼파라미터를 설정합니다.\n",
        "\n",
        "batchSize\n",
        "\n",
        "GPU 의 메모리 용량에는 한계가 있기 때문에, 모든 데이터를 한 번에 처리하지 못합니다.\n",
        "\n",
        "따라서, GPU 가 데이터를 조금씩 여러 번 처리하도록 설정해주어야 합니다.\n",
        "\n",
        "batchSize 는 GPU 가 처리하는 데이터의 개수를 의미합니다.\n",
        "\n",
        "learningRate\n",
        "\n",
        "Gradient descent  알고리즘에 사용하는 파라미터입니다.\n",
        "\n",
        "epochNum\n",
        "\n",
        "전체 데이터를 몇 번 학습할 것인지를 나타내는 변수입니다.\n",
        "\n",
        "epochNum = 100 이라면, 모델은 전체 데이터를 100 번씩 훑을 것입니다.\n",
        "\n",
        "device\n",
        "\n",
        "pyTorch 가 모델 학습 등 수치 계산을 위해 사용할 장비를 설정합니다.\n",
        "\n",
        "CPU 또는 GPU 를 사용하며, Colab 은 GPU 를 지원합니다."
      ]
    },
    {
      "metadata": {
        "id": "u91X0IPlQecV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchSize = 512\n",
        "learningRate = 0.01\n",
        "epochNum = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BqiN-bqoQSit",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "오늘 실습에 사용할 MNIST 데이터를 다운로드 받고, 읽어들입니다."
      ]
    },
    {
      "metadata": {
        "id": "H43uEV-8Sjsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ee9e751b-513f-40f9-8d3d-7bd611e07068"
      },
      "cell_type": "code",
      "source": [
        "# 학습 데이터\n",
        "# root      : ./data/mnist 라는 경로에 데이터를 저장\n",
        "# train     : 학습 데이터를 의미\n",
        "# download  : 지정한 경로에 데이터를 다운로드 함\n",
        "# transform : 데이터를 주어진 방법으로 변환함 (28 * 28 사이즈로 잘라내기 -> 텐서로 변환)\n",
        "dataTrain = torchvision.datasets.MNIST(root = './data/mnist',\n",
        "                                         train = True,\n",
        "                                         download = True,\n",
        "                                         transform = transforms.Compose([\n",
        "                                                        transforms.CenterCrop(28),\n",
        "                                                        transforms.ToTensor()]))\n",
        "\n",
        "# 테스트 데이터\n",
        "# root      : ./data/mnist 라는 경로에 데이터를 저장\n",
        "# train     : 테스트 데이터를 의미\n",
        "# download  : 지정한 경로에 데이터를 다운로드 함\n",
        "# transform : 데이터를 주어진 방법으로 변환함 (28 * 28 사이즈로 잘라내기 -> 텐서로 변환)\n",
        "dataTest = torchvision.datasets.MNIST(root = './data/mnist',\n",
        "                                         train = False,\n",
        "                                         download = True,\n",
        "                                         transform = transforms.Compose([\n",
        "                                                        transforms.CenterCrop(28),\n",
        "                                                        transforms.ToTensor()]))\n",
        "\n",
        "# 학습 데이터 로더\n",
        "# dataset    : 학습 데이터를 불러옴\n",
        "# batch_size : 위에서 지정한 batchSize 만큼 데이터를 불러옴\n",
        "# shuffle    : 랜덤한 순서로 데이터를 불러옴\n",
        "trainLoader = torch.utils.data.DataLoader(dataset = dataTrain, \n",
        "                                         batch_size = batchSize, \n",
        "                                         shuffle = True)\n",
        "\n",
        "# 테스트 데이터 로더\n",
        "# dataset    : 테스트 데이터를 불러옴\n",
        "# batch_size : 위에서 지정한 batchSize 만큼 데이터를 불러옴\n",
        "# shuffle    : 일정한 순서로 데이터를 불러옴\n",
        "testLoader = torch.utils.data.DataLoader(dataset = dataTest, \n",
        "                                         batch_size = batchSize, \n",
        "                                         shuffle = False)\n",
        "\n",
        "print('[info] batchSize : ', batchSize)\n",
        "print('[info] # of train batch : ', len(trainLoader))\n",
        "print('[info] # of test batch : ', len(testLoader))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "[info] batchSize :  512\n",
            "[info] # of train batch :  118\n",
            "[info] # of test batch :  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "671nTv-6VMO9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST 데이터를 화면에 표시하기 위한 함수를 정의하고,\n",
        "\n",
        "임의의 데이터를 출력해봅니다."
      ]
    },
    {
      "metadata": {
        "id": "Dy6uvYhHVMU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "d72da96e-2e32-469b-f773-c09d14323122"
      },
      "cell_type": "code",
      "source": [
        "def showImages(image, row):\n",
        "  \n",
        "  for _ in range(row):  \n",
        "  \n",
        "    idx = np.random.choice(100, 6)     # 0 ~ 99 의 정수 중 6 개를 임의로 선택\n",
        "    images =image.numpy()[idx]         # 선택된 index 에 해당하는 이미지를 가져옴\n",
        "    \n",
        "    plt.figure(figsize = (15, 90))     # 세로 길이 15, 가로 길이 15 * 6 의 화면 생성\n",
        "    \n",
        "    for i in range(161, 167):    \n",
        "    \n",
        "      plt.subplot(i)\n",
        "      plt.imshow(images[i - 161])\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])    \n",
        "    \n",
        "    plt.show()  \n",
        "\n",
        "for i, (image, labels) in enumerate(trainLoader): \n",
        "  \n",
        "  showImages(image.squeeze(), 3)\n",
        "  break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAACFCAYAAAC+N6IzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc0e51aa048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAACFCAYAAAC+N6IzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF2cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc094bab470>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAACFCAYAAAC+N6IzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naKYAAAAKaKYAAAAK/AfWLQ8J1nR9egAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc09210b3c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1UJjaRRRW_sM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "모델을 구현합니다.\n",
        "\n",
        "오늘 구현할 모델은 hidden layer 가 2 개인 fully connected neural network 입니다.\n",
        "\n",
        "hidden layer 의 노드 수는 각각 128 개, 64 개 이며, activation function 은 sigmoid 입니다."
      ]
    },
    {
      "metadata": {
        "id": "GhutNHNtW7B_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):                   # 모델 클래스를 선언\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(NeuralNetwork, self).__init__()        # nn.Module 을 비롯해 상위 클래스의 생성자를 호출 (문법입니다)\n",
        "    \n",
        "    self.hiddenLayer1 = nn.Linear(28 * 28, 128)  # 28 * 28 = 784 픽셀 (차원) 의 데이터를 받아 128 차원 벡터로 출력하는 레이어\n",
        "    self.hiddenLayer2 = nn.Linear(128, 64)       # 128 차원의 데이터를 받아 64 차원 벡터로 출력하는 레이어\n",
        "    self.outputLayer = nn.Linear(64, 10)         # 64 차원의 데이터를 받아 10 차원 벡터로 출력하는 레이어\n",
        "    self.sigmoid = nn.Sigmoid()                  # sigmoid activation function\n",
        "    \n",
        "  def forward(self, x):                          # 데이터를 받아 예측 결과를 출력하는 메소드 \n",
        "    \n",
        "    z2 = self.hiddenLayer1(x)                    # 첫 번째 hidden layer 를 통과한 결과\n",
        "    a2 = self.sigmoid(z2)                        # 위의 값을 sigmoid 에 통과한 결과\n",
        "    \n",
        "    z3 = self.hiddenLayer2(a2)                   # 두 번째 hidden layer 를 통과한 결과\n",
        "    a3 = self.sigmoid(z3)                        # 위의 값을 sigmoid 에 통과한 결과\n",
        "    \n",
        "    z4 = self.outputLayer(a3)                    # 마지막 layer 를 통과한 결과\n",
        "    y = self.sigmoid(z4)                         # 위의 값을 sigmoid 에 통과한 결과 (최종 출력)\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auX7TQbIY0eB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "모델을 생성하고, 학습 전의 성능을 측정해봅니다."
      ]
    },
    {
      "metadata": {
        "id": "5xuYS4mLgiwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e2c4f6c-213c-461b-8683-afe9cf03e8bf"
      },
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)                      # 모델을 생성하고 GPU 로 전송\n",
        "\n",
        "model.eval()                                            # 모델을 테스트 모드로 전환 (학습 때와 테스트 때의 forward 기능이 달라야 하는 경우가 존재합니다, 이후에 배울 예정입니다.)\n",
        "\n",
        "with torch.no_grad():                                   # Gradient 계산 x (테스트할 때에는 gradient 가 필요 없으므로 메모리 절약을 위해 gradient 계산을 하지 않습니다.)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  for images, labels in testLoader:\n",
        "    \n",
        "    images = images.reshape(-1, 28 * 28).to(device)     # 가로 28, 세로 28 의 2 차원 MNIST 이미지를 784 차원의 1 차원 벡터로 변환하고 GPU 로 전송\n",
        "    labels = labels.to(device)                          # MNIST 데이터의 정답, GPU 로 전송\n",
        "    \n",
        "    outputs = model(images)                             # MNIST 이미지가 모델을 통과하고 나온 결과 (classification 결과입니다.)\n",
        "    _, predicted = torch.max(outputs.data, 1)           # classification 결과와 정답을 비교해 맞은 갯수를 셈 (sigmoid output 의 값이 가장 큰 것이 예측된 class 입니다.)\n",
        "    \n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 11.35 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XsKXvkF9gi2h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "본격적으로 학습을 시작합니다.\n",
        "\n",
        "Cost function 은 cross entropy loss 입니다."
      ]
    },
    {
      "metadata": {
        "id": "rTXueqZaY0k1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "67ec0b5e-a64f-4724-d9cf-cbf027e73cf7"
      },
      "cell_type": "code",
      "source": [
        "model.train()                                                          # 모델을 학습 모드로 전환 (학습 때와 테스트 때의 forward 기능이 달라야 하는 경우가 존재합니다, 이후에 배울 예정입니다.)\n",
        "\n",
        "costFunction = nn.CrossEntropyLoss()                                   # Cross entropy 를 cost function 으로 사용\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learningRate)    # Adam 이라는 optimizer 를 사용 (이후에 배울 예정)\n",
        "\n",
        "totalStep = len(trainLoader)\n",
        "\n",
        "for epoch in range(epochNum):\n",
        "  \n",
        "    for idx, (images, labels) in enumerate(trainLoader):\n",
        "      \n",
        "        images = images.reshape(-1, 28 * 28).to(device)                 # 가로 28, 세로 28 의 2 차원 MNIST 이미지를 784 차원의 1 차원 벡터로 변환하고 GPU 로 전송\n",
        "        labels = labels.to(device)                                      # MNIST 데이터의 정답, GPU 로 전송\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)                                         # MNIST 이미지가 모델을 통과하고 나온 결과 (classification 결과입니다.)\n",
        "        loss = costFunction(outputs, labels)                            # Classification 결과와 실제 정답을 비교해 cost function 값을 계산\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()                                           # gradient 값을 초기화 (pyTorch 에서는 gradient 를 계산할 때마다 값이 누적됩니다.)\n",
        "        loss.backward()                                                 # cost function 값을 토대로 gradient 를 계산\n",
        "        optimizer.step()                                                # 계산한 gradient 값으로 모델의 파라미터를 업데이트\n",
        "        \n",
        "        if (idx + 1) % 100 == 0:\n",
        "            \n",
        "            print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\".format(epoch + 1, epochNum, idx + 1, totalStep, loss.item()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/118] Loss: 1.5699\n",
            "Epoch [2/10], Step [100/118] Loss: 1.5216\n",
            "Epoch [3/10], Step [100/118] Loss: 1.5007\n",
            "Epoch [4/10], Step [100/118] Loss: 1.4932\n",
            "Epoch [5/10], Step [100/118] Loss: 1.4808\n",
            "Epoch [6/10], Step [100/118] Loss: 1.4824\n",
            "Epoch [7/10], Step [100/118] Loss: 1.4760\n",
            "Epoch [8/10], Step [100/118] Loss: 1.4735\n",
            "Epoch [9/10], Step [100/118] Loss: 1.4728\n",
            "Epoch [10/10], Step [100/118] Loss: 1.4731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IdgLG0wVbH0_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "학습한 모델의 성능을 테스트 데이터를 이용해 확인합니다."
      ]
    },
    {
      "metadata": {
        "id": "97K9soU_bHoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9fdb870-df42-454e-e71b-32bbbbf27b7e"
      },
      "cell_type": "code",
      "source": [
        "model.eval()                                            # 모델을 테스트 모드로 전환 (학습 때와 테스트 때의 forward 기능이 달라야 하는 경우가 존재합니다, 이후에 배울 예정입니다.)\n",
        "\n",
        "with torch.no_grad():                                   # Gradient 계산 x (테스트할 때에는 gradient 가 필요 없으므로 메모리 절약을 위해 gradient 계산을 하지 않습니다.)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  for images, labels in testLoader:\n",
        "    \n",
        "    images = images.reshape(-1, 28 * 28).to(device)     # 가로 28, 세로 28 의 2 차원 MNIST 이미지를 784 차원의 1 차원 벡터로 변환하고 GPU 로 전송\n",
        "    labels = labels.to(device)                          # MNIST 데이터의 정답, GPU 로 전송\n",
        "    \n",
        "    outputs = model(images)                             # MNIST 이미지가 모델을 통과하고 나온 결과 (classification 결과입니다.)\n",
        "    _, predicted = torch.max(outputs.data, 1)           # classification 결과와 정답을 비교해 맞은 갯수를 셈 (sigmoid output 의 값이 가장 큰 것이 예측된 class 입니다.)\n",
        "    \n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 97.13 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EWn-_a0hhZaJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이제 새로운 모델을 직접 만들어 봅시다."
      ]
    },
    {
      "metadata": {
        "id": "3yiHn_CicPks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "d71RTGqwhdVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NeuralNetwork2(nn.Module):                  # 모델 클래스를 선언\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(NeuralNetwork2, self).__init__()        # nn.Module 을 비롯해 상위 클래스의 생성자를 호출 (문법입니다)\n",
        "    \n",
        "    # hidden layer 의 노드가 각각 384, 256, 128, 64 인 5-layer model 을 만들어보세요.\n",
        "    ########## 코드를 채워주세요 ##########\n",
        "    \n",
        "    self.hiddenLayer1 = nn.Linear(28 * 28, 384)  # 28 * 28 = 784 픽셀 (차원) 의 데이터를 받아 384 차원 벡터로 출력하는 레이어\n",
        "    self.hiddenLayer2 = nn.Linear(384, 256)      # 384 픽셀 (차원) 의 데이터를 받아 256 차원 벡터로 출력하는 레이어\n",
        "    self.hiddenLayer3 = nn.Linear(256, 128)      # 256 픽셀 (차원) 의 데이터를 받아 128 차원 벡터로 출력하는 레이어\n",
        "    self.hiddenLayer4 = nn.Linear(128, 64)       # 128 차원의 데이터를 받아 64 차원 벡터로 출력하는 레이어\n",
        "    self.outputLayer = nn.Linear(64, 10)         # 64 차원의 데이터를 받아 10 차원 벡터로 출력하는 레이어\n",
        "    self.sigmoid = nn.Sigmoid()                  # sigmoid activation function\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #######################################\n",
        "    \n",
        "    self.sigmoid = nn.Sigmoid()                  # sigmoid activation function\n",
        "    \n",
        "  def forward(self, x):                          # 데이터를 받아 예측 결과를 출력하는 메소드 \n",
        "    \n",
        "    # activation function 은 sigmoid 를 사용해주세요.\n",
        "    ########## 코드를 채워주세요 ##########\n",
        "    \n",
        "    out = x\n",
        "    out = self.sigmoid(self.hiddenLayer1(out))\n",
        "    out = self.sigmoid(self.hiddenLayer2(out))\n",
        "    out = self.sigmoid(self.hiddenLayer3(out))\n",
        "    out = self.sigmoid(self.hiddenLayer4(out))\n",
        "    out = self.sigmoid(self.outputLayer(out))\n",
        "    y = out\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #######################################\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N85oc54Qi4mG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "새로운 모델을 학습하고, 테스트 결과를 확인해보세요."
      ]
    },
    {
      "metadata": {
        "id": "GnNs9SL7i2ZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "79faa157-58ee-4f69-c5d7-e4ec41f1b1bb"
      },
      "cell_type": "code",
      "source": [
        "model2 = NeuralNetwork2().to(device)\n",
        "model2.train()                                                          # 모델을 학습 모드로 전환 (학습 때와 테스트 때의 forward 기능이 달라야 하는 경우가 존재합니다, 이후에 배울 예정입니다.)\n",
        "\n",
        "costFunction = nn.CrossEntropyLoss()                                    # Cross entropy 를 cost function 으로 사용\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr = learningRate)    # Adam 이라는 optimizer 를 사용 (이후에 배울 예정)\n",
        "\n",
        "totalStep = len(trainLoader)\n",
        "\n",
        "for epoch in range(epochNum):\n",
        "  \n",
        "    for idx, (images, labels) in enumerate(trainLoader):\n",
        "      \n",
        "        images = images.reshape(-1, 28 * 28).to(device)                 # 가로 28, 세로 28 의 2 차원 MNIST 이미지를 784 차원의 1 차원 벡터로 변환하고 GPU 로 전송\n",
        "        labels = labels.to(device)                                      # MNIST 데이터의 정답, GPU 로 전송\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model2(images)                                        # MNIST 이미지가 모델을 통과하고 나온 결과 (classification 결과입니다.)\n",
        "        loss = costFunction(outputs, labels)                            # Classification 결과와 실제 정답을 비교해 cost function 값을 계산\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()                                           # gradient 값을 초기화 (pyTorch 에서는 gradient 를 계산할 때마다 값이 누적됩니다.)\n",
        "        loss.backward()                                                 # cost function 값을 토대로 gradient 를 계산\n",
        "        optimizer.step()                                                # 계산한 gradient 값으로 모델의 파라미터를 업데이트\n",
        "        \n",
        "        if (idx + 1) % 100 == 0:\n",
        "            \n",
        "            print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\".format(epoch + 1, epochNum, idx + 1, totalStep, loss.item()))\n",
        "            \n",
        "model2.eval()                                           # 모델을 테스트 모드로 전환 (학습 때와 테스트 때의 forward 기능이 달라야 하는 경우가 존재합니다, 이후에 배울 예정입니다.)\n",
        "\n",
        "with torch.no_grad():                                   # Gradient 계산 x (테스트할 때에는 gradient 가 필요 없으므로 메모리 절약을 위해 gradient 계산을 하지 않습니다.)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  for images, labels in testLoader:\n",
        "    \n",
        "    images = images.reshape(-1, 28 * 28).to(device)     # 가로 28, 세로 28 의 2 차원 MNIST 이미지를 784 차원의 1 차원 벡터로 변환하고 GPU 로 전송\n",
        "    labels = labels.to(device)                          # MNIST 데이터의 정답, GPU 로 전송\n",
        "    \n",
        "    outputs = model2(images)                            # MNIST 이미지가 모델을 통과하고 나온 결과 (classification 결과입니다.)\n",
        "    _, predicted = torch.max(outputs.data, 1)           # classification 결과와 정답을 비교해 맞은 갯수를 셈 (sigmoid output 의 값이 가장 큰 것이 예측된 class 입니다.)\n",
        "    \n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/118] Loss: 1.7874\n",
            "Epoch [2/10], Step [100/118] Loss: 1.7494\n",
            "Epoch [3/10], Step [100/118] Loss: 1.7411\n",
            "Epoch [4/10], Step [100/118] Loss: 1.6149\n",
            "Epoch [5/10], Step [100/118] Loss: 1.6296\n",
            "Epoch [6/10], Step [100/118] Loss: 1.6093\n",
            "Epoch [7/10], Step [100/118] Loss: 1.6062\n",
            "Epoch [8/10], Step [100/118] Loss: 1.5543\n",
            "Epoch [9/10], Step [100/118] Loss: 1.5140\n",
            "Epoch [10/10], Step [100/118] Loss: 1.5068\n",
            "Test Accuracy of the model on the 10000 test images: 88.66 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZTN-RhRJjnNl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "왜 레이어를 더 쌓았는데, 결과가 떨어졌을까요?"
      ]
    }
  ]
}